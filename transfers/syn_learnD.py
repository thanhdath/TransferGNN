# -*- coding: utf-8 -*-
import os
from sklearn.metrics import f1_score
"""ppi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i8xRqB1bvfLoTvICrMtHFuvKqdvU5x6D
"""

# !pip install dgl-cu101

import dgl
from dgl.data.ppi import PPIDataset

from dgl.data.ppi import LegacyPPIDataset
from torch.utils.data import DataLoader
import torch
import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
import sys
import argparse 

parser = argparse.ArgumentParser()
parser.add_argument('--seed', type=int, default=100)
parser.add_argument('--data', default="data-transfers/syn-seed100/")
args = parser.parse_args()
np.random.seed(args.seed)
torch.manual_seed(args.seed)

def collate(sample):
    graphs, feats, labels = map(list, zip(*sample))
    graph = dgl.batch(graphs)
    feats = torch.from_numpy(np.concatenate(feats))
    labels = torch.from_numpy(np.concatenate(labels))
    return graph, feats, labels

import pandas as pd
F1 = np.load(f"{args.data}/0/features.npz", allow_pickle=True)["features"][()]
A1 = np.zeros((len(F1), len(F1)))
edgelist = pd.read_csv(f"{args.data}/0/syn0.txt", sep=" ", header=None).values.astype(np.int)
A1[edgelist[:,0], edgelist[:,1]] = 1
L1 = pd.read_csv(f"{args.data}/0/labels.txt", sep=" ", header=None).values.astype(np.int)[:,1]
F2 = np.load(f"{args.data}/1/features.npz", allow_pickle=True)["features"][()]
A2 = np.zeros((len(F2), len(F2)))
edgelist = pd.read_csv(f"{args.data}/1/syn1.txt", sep=" ", header=None).values.astype(np.int)
A2[edgelist[:,0], edgelist[:,1]] = 1
L2 = pd.read_csv(f"{args.data}/1/labels.txt", sep=" ", header=None).values.astype(np.int)[:,1]
A1 = torch.FloatTensor(A1).cuda()
A2 = torch.FloatTensor(A2).cuda()
# L1 = torch.FloatTensor(L1).cuda()
# L2 = torch.FloatTensor(L2).cuda()
    
def compute_f1(pA, A):
    pA = pA.detach().cpu().numpy()
    pA[pA >= 0.5] = 1
    pA[pA < 0.5] = 0
    A = A.cpu().numpy()
    f1 = f1_score(A, pA, average="micro")
    return f1

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        # self.D1 = torch.FloatTensor(F1).cuda()
        # self.D2 = torch.FloatTensor(F2).cuda()
        self.D1 = nn.Parameter(torch.empty(F1.shape).normal_(mean=0., std=1.)).cuda()
        self.D2 = nn.Parameter(torch.empty(F2.shape).normal_(mean=0., std=1.)).cuda()
        fdim = self.D1.shape[1]
        self.W = nn.Sequential(
            nn.Linear(fdim, fdim*2, bias=True),
            nn.ReLU(),
            nn.Linear(fdim*2, fdim*2, bias=True),
            nn.ReLU(),
            nn.Linear(fdim*2, fdim, bias=True),
        )

    def forward(self):
        D1 = self.W(self.D1)
        # x1 = D1.mm(D1.t())
        x1 = torch.pdist(D1)
        D2 = self.W(self.D2)
        # x2 = D2.mm(D2.t())
        x2 = torch.pdist(D2)
        return x1, x2



model = Model().cuda()
loss_fn = nn.MSELoss()
optim = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

inds1 = torch.triu(torch.ones(len(A1),len(A1))) 
inds1[np.arange(len(A1)), np.arange(len(A1))] = 0
halfA1 = A1[inds1 == 1]
inds2 = torch.triu(torch.ones(len(A2),len(A2))) 
inds2[np.arange(len(A2)), np.arange(len(A2))] = 0
halfA2 = A2[inds2 == 1]


for iter in range(400):
    model.train()
    optim.zero_grad()
    pred_A1, pred_A2 = model()
    loss = loss_fn(pred_A1, halfA1) + loss_fn(pred_A2, halfA2)
    loss.backward()
    optim.step()
    if iter % 50 == 0:
        microf11 = compute_f1(pred_A1, halfA1)
        microf12 = compute_f1(pred_A2, halfA2)
        print(f"Iter {iter} - loss {loss:.4f} - f1 {microf11:.3f}  {microf12:.3f}")

# gen edgelist, labels, featuresh
print("Save graphs")
X1 = F1
X2 = F2
features = X1
edgelist = np.argwhere(A1.detach().cpu().numpy() > 0)
labels = L1

outdir = f"data-transfers/synD-seed{args.seed}/0"
if not os.path.isdir(outdir):
    os.makedirs(outdir)

with open(outdir + f"/0.txt", "w+") as fp:
    for src, trg in edgelist:
        fp.write(f"{src} {trg}\n")
with open(outdir + "/labels.txt", "w+") as fp:
    for i, label in enumerate(labels):
        fp.write(f"{i} {label}\n")
np.savez_compressed(outdir + "/features.npz", features=features)

features = X2
edgelist = np.argwhere(A2.detach().cpu().numpy() > 0)
labels = L2

outdir = f"data-transfers/synD-seed{args.seed}/1"
if not os.path.isdir(outdir):
    os.makedirs(outdir)

with open(outdir + f"/1.txt", "w+") as fp:
    for src, trg in edgelist:
        fp.write(f"{src} {trg}\n")
with open(outdir + "/labels.txt", "w+") as fp:
    for i, label in enumerate(labels):
        fp.write(f"{i} {label}\n")
np.savez_compressed(outdir + "/features.npz", features=features)

